{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1259db-f48d-4399-95e4-6b86aea96a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 19:09:36] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> To use the Graphein submodule                                         <a href=\"file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/features/sequence/embeddings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">embeddings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/features/sequence/embeddings.py#44\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         graphein.protein.features.sequence.embeddings, you need to install:   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         biovec                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         biovec cannot be installed via conda                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Alternatively, you can install graphein with the extras:              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pip install graphein<span style=\"font-weight: bold\">[</span>extras<span style=\"font-weight: bold\">]</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 19:09:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m To use the Graphein submodule                                         \u001b]8;id=998916;file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/features/sequence/embeddings.py\u001b\\\u001b[2membeddings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=859622;file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/features/sequence/embeddings.py#44\u001b\\\u001b[2m44\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         graphein.protein.features.sequence.embeddings, you need to install:   \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         biovec                                                                \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         biovec cannot be installed via conda                                  \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Alternatively, you can install graphein with the extras:              \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                               \u001b[2m                \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         pip install graphein\u001b[1m[\u001b[0mextras\u001b[1m]\u001b[0m                                          \u001b[2m                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 19:09:39] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> To use the Graphein submodule graphein.protein.visualisation, you  <a href=\"file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/visualisation.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">visualisation.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/visualisation.py#35\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         need to install: pytorch3d                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To do so, use the following command: conda install -c pytorch3d    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         pytorch3d                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 19:09:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m To use the Graphein submodule graphein.protein.visualisation, you  \u001b]8;id=514819;file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/visualisation.py\u001b\\\u001b[2mvisualisation.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=99621;file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/visualisation.py#35\u001b\\\u001b[2m35\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         need to install: pytorch3d                                         \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To do so, use the following command: conda install -c pytorch3d    \u001b[2m                   \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         pytorch3d                                                          \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> To use the Graphein submodule graphein.protein.meshes, you need to        <a href=\"file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/meshes.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">meshes.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/meshes.py#29\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">29</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         install: pytorch3d                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To do so, use the following command: conda install -c pytorch3d pytorch3d <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m To use the Graphein submodule graphein.protein.meshes, you need to        \u001b]8;id=332507;file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/meshes.py\u001b\\\u001b[2mmeshes.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=211772;file:///zhome/6e/5/146981/.local/lib/python3.9/site-packages/graphein/protein/meshes.py#29\u001b\\\u001b[2m29\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         install: pytorch3d                                                        \u001b[2m            \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         To do so, use the following command: conda install -c pytorch3d pytorch3d \u001b[2m            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from task import CreateDataLabel,MapAtomNode,node_accuracy\n",
    "from schnet import SchNetModel\n",
    "#from proteinworkshop.models.graph_encoders.schnet import SchNetModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ae7c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:10:28] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Amending traindata                                                          <a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">task.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py#78\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">78</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:10:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Amending traindata                                                          \u001b]8;id=48946;file:///work3/s194408/Project/schnet_majorvoting/task.py\u001b\\\u001b[2mtask.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=363645;file:///work3/s194408/Project/schnet_majorvoting/task.py#78\u001b\\\u001b[2m78\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:10:29] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2381</span> examples in train                                         <a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:10:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m2381\u001b[0m examples in train                                         \u001b]8;id=866064;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=890192;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\u001b\\\u001b[2m307\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Structure Analysis Using Geometric: 100%|███| 2381/2381 [01:21<00:00, 29.34it/s]\n",
      "Finding dismatch and processing ...: 100%|█| 2381/2381 [00:11<00:00, 198.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:15:37] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Have finshed finding dismatch and processing, after processing not   <a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#143\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         founded dismatch                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:15:37]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Have finshed finding dismatch and processing, after processing not   \u001b]8;id=860423;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=661208;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#143\u001b\\\u001b[2m143\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         founded dismatch                                                     \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing train data                                                       <a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">task.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing train data                                                       \u001b]8;id=416466;file:///work3/s194408/Project/schnet_majorvoting/task.py\u001b\\\u001b[2mtask.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=148536;file:///work3/s194408/Project/schnet_majorvoting/task.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Structure Analysis Using Geometric: 100%|███| 2381/2381 [01:21<00:00, 29.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:20:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing train labels                                                     <a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">task.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py#87\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">87</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:20:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing train labels                                                     \u001b]8;id=285296;file:///work3/s194408/Project/schnet_majorvoting/task.py\u001b\\\u001b[2mtask.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=529010;file:///work3/s194408/Project/schnet_majorvoting/task.py#87\u001b\\\u001b[2m87\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:20:55] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2381</span> examples in train                                         <a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:20:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m2381\u001b[0m examples in train                                         \u001b]8;id=339743;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=566342;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\u001b\\\u001b[2m307\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train node label: 100%|████████| 2381/2381 [00:01<00:00, 1723.87it/s]\n",
      "Processing train atom label: 100%|████████| 2381/2381 [00:01<00:00, 1918.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:20:58] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Amending valdata                                                            <a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">task.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py#78\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">78</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:20:58]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Amending valdata                                                            \u001b]8;id=258808;file:///work3/s194408/Project/schnet_majorvoting/task.py\u001b\\\u001b[2mtask.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=291794;file:///work3/s194408/Project/schnet_majorvoting/task.py#78\u001b\\\u001b[2m78\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:20:59] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">596</span> examples in val                                            <a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:20:59]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m596\u001b[0m examples in val                                            \u001b]8;id=897577;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=486372;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\u001b\\\u001b[2m307\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Structure Analysis Using Geometric: 100%|█████| 596/596 [00:19<00:00, 31.20it/s]\n",
      "Finding dismatch and processing ...: 100%|███| 596/596 [00:02<00:00, 229.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:22:15] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Have finshed finding dismatch and processing, after processing not   <a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#143\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         founded dismatch                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:22:15]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Have finshed finding dismatch and processing, after processing not   \u001b]8;id=772053;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=331401;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#143\u001b\\\u001b[2m143\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         founded dismatch                                                     \u001b[2m                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing val data                                                         <a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">task.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py#82\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">82</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing val data                                                         \u001b]8;id=807031;file:///work3/s194408/Project/schnet_majorvoting/task.py\u001b\\\u001b[2mtask.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=202963;file:///work3/s194408/Project/schnet_majorvoting/task.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Structure Analysis Using Geometric: 100%|█████| 596/596 [00:18<00:00, 32.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/11/23 10:23:29] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Processing val labels                                                       <a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">task.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/task.py#87\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">87</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/11/23 10:23:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Processing val labels                                                       \u001b]8;id=655951;file:///work3/s194408/Project/schnet_majorvoting/task.py\u001b\\\u001b[2mtask.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=224358;file:///work3/s194408/Project/schnet_majorvoting/task.py#87\u001b\\\u001b[2m87\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Found <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">596</span> examples in val                                            <a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Found \u001b[1;36m596\u001b[0m examples in val                                            \u001b]8;id=556068;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py\u001b\\\u001b[2mdata_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=945323;file:///work3/s194408/Project/schnet_majorvoting/data_utils.py#307\u001b\\\u001b[2m307\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing val node label: 100%|████████████| 596/596 [00:00<00:00, 1964.62it/s]\n",
      "Processing val atom label: 100%|████████████| 596/596 [00:00<00:00, 1840.25it/s]\n"
     ]
    }
   ],
   "source": [
    "##['train', 'val', 'test_SP_TM', 'test_TM', 'test_BETA']\n",
    "batch_size = 1\n",
    "raw_data_name = \"DeepTMHMM.3line\"\n",
    "path ='/work3/s194408/Project/'\n",
    "processor = CreateDataLabel(path,batch_size =batch_size,raw_data_name=raw_data_name)\n",
    "# processor.initialization()# split and download trian/val/test just once\n",
    "\n",
    "train_data,train_lable, train_batchname, train_max_len,train_dismatch_index_pred,train_dismatch_index_type,train_real_node_label,df_train = processor.datalabelgenerator('train')\n",
    "\n",
    "val_data,val_lable, val_batchname, val_max_len,val_dismatch_index_pred,val_dismatch_index_type,val_real_node_label,df_val = processor.datalabelgenerator('val')\n",
    "\n",
    "test_SP_TM_data,test_SP_TM_lable, test_SP_TM_batchname, test_SP_TM_max_len,test_SP_TM_dismatch_index_pred,test_SP_TM_dismatch_index_type,test_SP_TM_real_node_label,df_test_SP_TM = processor.datalabelgenerator('test_SP_TM')\n",
    "\n",
    "test_TM_data,test_TM_lable, test_TM_batchname, test_TM_max_len,test_TM_dismatch_index_pred,test_TM_dismatch_index_type,test_TM_real_node_label,df_test_TM = processor.datalabelgenerator('test_TM')\n",
    "\n",
    "test_BETA_data,test_BETA_lable, test_BETA_batchname, test_BETA_max_len,test_BETA_dismatch_index_pred,test_BETA_dismatch_index_type,test_BETA_real_node_label,df_test_BETA = processor.datalabelgenerator('test_BETA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a083a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms194408\u001b[0m (\u001b[33mtransmembrane-topology\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work3/s194408/Project/schnet_majorvoting/wandb/run-20231208_113009-eeae6a0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/transmembrane-topology/DL_tmp/runs/eeae6a0n' target=\"_blank\">batchsize 8 </a></strong> to <a href='https://wandb.ai/transmembrane-topology/DL_tmp' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/transmembrane-topology/DL_tmp' target=\"_blank\">https://wandb.ai/transmembrane-topology/DL_tmp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/transmembrane-topology/DL_tmp/runs/eeae6a0n' target=\"_blank\">https://wandb.ai/transmembrane-topology/DL_tmp/runs/eeae6a0n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f8927005dc0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f8927005670, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f892703f6d0, raw_cell=\"# start a new wandb run to track this script\n",
      "wandb..\" store_history=True silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"DL_tmp\", #项目名称\n",
    "    entity=\"transmembrane-topology\", # 用户名\n",
    "    group=\"major voting\", # 对比实验分组\n",
    "    name= \"batchsize 1 with weight \", #实验的名字\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"schnet\",\n",
    "    \"dataset\": \"protein 3D structures \",\n",
    "    \"epochs\":150,\n",
    "    'batch_size':8,\n",
    "    'hidden_channels' :256,\n",
    "    'weight_decay': 1e-4\n",
    "    }\n",
    ")\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41b3a8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'max_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#max_len=max(train_max_len,val_max_len,test_SP_TM_max_len,test_TM_max_len,test_BETA_max_len)+1 #StaticEmbedding need max_len\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# put model to GPU\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSchNetModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'max_len'"
     ]
    }
   ],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#max_len=max(train_max_len,val_max_len,test_SP_TM_max_len,test_TM_max_len,test_BETA_max_len)+1 #StaticEmbedding need max_len\n",
    "# put model to GPU\n",
    "#model = SchNetModel(hidden_channels=256, out_dim=6, max_len=30000).to(device)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#max_len=max(train_max_len,val_max_len,test_SP_TM_max_len,test_TM_max_len,test_BETA_max_len)+1 #StaticEmbedding need max_len\n",
    "# put model to GPU\n",
    "model = SchNetModel(hidden_channels=256, out_dim=6).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001,weight_decay=1e-4)\n",
    "\n",
    "chk_path = '/work3/s194408/Project/schnet_weight/ca_bb/last.ckpt'\n",
    "checkpoint  = torch.load(chk_path, map_location=torch.device('cpu'))\n",
    "\n",
    "model.load_state_dict(checkpoint, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3c7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2eaf53-7d2e-43fb-9081-a0c731608cde",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \n\u001b[0;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# put batch data in GPU get logits\u001b[39;00m\n\u001b[1;32m     21\u001b[0m prediction \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \n\u001b[1;32m     22\u001b[0m real_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(torch\u001b[38;5;241m.\u001b[39mtensor(train_lable[i]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# put label in GPU\u001b[39;00m\n",
      "File \u001b[0;32m/work3/s194408/miniconda3/envs/proteinworkshop/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/work3/s194408/ProteinWorkshop/proteinworkshop/models/graph_encoders/schnet.py:103\u001b[0m, in \u001b[0;36mSchNetModel.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Union[Batch, ProteinBatch]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EncoderOutput:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implements the forward pass of the SchNet encoder.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    Returns the node embedding and graph embedding in a dictionary.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    :rtype: EncoderOutput\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     u, v \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m    106\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m (batch\u001b[38;5;241m.\u001b[39mpos[u] \u001b[38;5;241m-\u001b[39m batch\u001b[38;5;241m.\u001b[39mpos[v])\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/work3/s194408/miniconda3/envs/proteinworkshop/lib/python3.9/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m/work3/s194408/miniconda3/envs/proteinworkshop/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "total_epochs=150\n",
    "draw_num = 1\n",
    "global_step = 0\n",
    "\n",
    "\n",
    "epoch_atom_level_accuracy_record_train = []\n",
    "epoch_loss_record_train=[]\n",
    "epoch_node_level_accuracy_record_train = []\n",
    "epoch_atom_level_accuracy_record_val = []\n",
    "epoch_loss_record_val = []\n",
    "epoch_node_level_accuracy_record_val = []\n",
    "for epoch in range(total_epochs):\n",
    "    epoch_atom_level_accuracy_train = []\n",
    "    epoch_loss_train=[]\n",
    "    epoch_node_level_accuracy_train = []\n",
    "    # train\n",
    "    for i, data in enumerate(train_data):  \n",
    "        global_step += 1 \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(data.to(device))   # put batch data in GPU get logits\n",
    "        prediction = outputs[\"node_embedding\"]  \n",
    "        real_label = torch.argmax(torch.tensor(train_lable[i]), dim=1).to(device) # put label in GPU\n",
    "        loss = criterion(prediction, real_label)  # operate in the same device\n",
    "        loss.backward()     \n",
    "        optimizer.step()    \n",
    "\n",
    "        #calulate atom-level accuracy and node-level accuracy\n",
    "        _, predicted = torch.max(prediction, 1) \n",
    "        correct = (predicted == real_label).sum().item()\n",
    "        total = real_label.size(0)\n",
    "        atom_level_accuracy =  correct / total\n",
    "\n",
    "        # below is operated under CPU node\n",
    "        processor = MapAtomNode(predicted.cpu(),train_batchname[i],train_dismatch_index_pred,train_dismatch_index_type,df_train)\n",
    "\n",
    "        train_predict_node_label = processor.map_atom_node() \n",
    "        node_level_accuracy = node_accuracy(train_predict_node_label,train_real_node_label[i])\n",
    "\n",
    "        wandb.log({'train_loss_step':loss.item(), 'global_step':global_step})\n",
    "        wandb.log({'train_atom_level_accuracy_step':atom_level_accuracy,  'global_step':global_step})\n",
    "        wandb.log({'train_node_level_accuracy_step':node_level_accuracy, 'global_step':global_step})\n",
    "\n",
    "        epoch_loss_train.append(loss.item())\n",
    "        epoch_atom_level_accuracy_train.append(atom_level_accuracy)\n",
    "        epoch_node_level_accuracy_train.append(node_level_accuracy)\n",
    "        \n",
    "    epoch_loss_record_train.append(np.mean(epoch_loss_train))\n",
    "    epoch_atom_level_accuracy_record_train.append(np.mean(epoch_atom_level_accuracy_train))\n",
    "    epoch_node_level_accuracy_record_train.append(np.mean(epoch_node_level_accuracy_train))\n",
    "\n",
    "    wandb.log({'train_loss_epoch':np.mean(epoch_loss_train), 'global_step':global_step})\n",
    "    wandb.log({'train_atom_level_accuracy_epoch':np.mean(epoch_atom_level_accuracy_train),  'global_step':global_step})\n",
    "    wandb.log({'train_node_level_accuracy_epoch':np.mean(epoch_node_level_accuracy_train), 'global_step':global_step})\n",
    "    \n",
    "    # val\n",
    "    model.eval()  \n",
    "    with torch.no_grad():  \n",
    "\n",
    "        epoch_atom_level_accuracy_val = []\n",
    "        epoch_loss_val = []\n",
    "        epoch_node_level_accuracy_val = []\n",
    "        \n",
    "        for i, data in enumerate(val_data):  \n",
    "            outputs = model(data.to(device))\n",
    "            prediction = outputs[\"node_embedding\"]\n",
    "            real_label = torch.argmax(torch.tensor(val_lable[i]), dim=1).to(device)\n",
    "            loss = criterion(prediction, real_label)\n",
    "\n",
    "            \n",
    "            _, predicted = torch.max(prediction, 1)\n",
    "            correct = (predicted == real_label).sum().item()\n",
    "            total = real_label.size(0)\n",
    "            atom_level_accuracy = correct / total\n",
    "\n",
    "            processor = MapAtomNode(predicted.cpu(), val_batchname[i], val_dismatch_index_pred, val_dismatch_index_type, df_val)\n",
    "            val_predict_node_label = processor.map_atom_node()\n",
    "            node_level_accuracy = node_accuracy(val_predict_node_label, val_real_node_label[i])\n",
    "\n",
    "            epoch_loss_val.append(loss.item())\n",
    "            epoch_atom_level_accuracy_val.append(atom_level_accuracy)\n",
    "            epoch_node_level_accuracy_val.append(node_level_accuracy)\n",
    "            \n",
    "            wandb.log({'val_loss_step':loss.item(), 'global_step':global_step})\n",
    "            wandb.log({'val_atom_level_accuracy_step':atom_level_accuracy,  'global_step':global_step})\n",
    "            wandb.log({'val_node_level_accuracy_step':node_level_accuracy, 'global_step':global_step})\n",
    "\n",
    "\n",
    "            epoch_loss_val.append(loss.item())\n",
    "            epoch_atom_level_accuracy_val.append(atom_level_accuracy)\n",
    "            epoch_node_level_accuracy_val.append(node_level_accuracy)\n",
    "            \n",
    "        epoch_loss_record_val.append(np.mean(epoch_loss_val))\n",
    "        epoch_atom_level_accuracy_record_val.append(np.mean(epoch_atom_level_accuracy_val))\n",
    "        epoch_node_level_accuracy_record_val.append(np.mean(epoch_node_level_accuracy_val))\n",
    "\n",
    "        wandb.log({'val_loss_epoch':np.mean(epoch_loss_val), 'global_step':global_step})\n",
    "        wandb.log({'val_atom_level_accuracy_epoch':np.mean(epoch_atom_level_accuracy_val), 'global_step':global_step})\n",
    "        wandb.log({'val_node_level_accuracy_epoch':np.mean(epoch_node_level_accuracy_val), 'global_step':global_step})\n",
    "\n",
    "    if epoch % draw_num == 0:\n",
    "        print(f\"EPOCH:{epoch}:Train Loss:{np.mean(epoch_loss_train)} Train Atom Level Accuracy:{np.mean(epoch_atom_level_accuracy_train)} Train Node Level Accuracy:{np.mean(epoch_node_level_accuracy_train)}\")\n",
    "        print(f\"EPOCH:{epoch}:Val Loss:{np.mean(epoch_loss_val)} Val Atom Level Accuracy:{np.mean(epoch_atom_level_accuracy_val)} Val Node Level Accuracy:{np.mean(epoch_node_level_accuracy_val)}\")\n",
    "\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "\n",
    "print(\"Finished training.\")\n",
    "\n",
    "torch.save(model.state_dict(), '/work3/s194408/Project/result/test_model.pth')\n",
    "\n",
    "   \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f839a384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['embedding.embedding.weight', 'distance_expansion.offset', 'interactions.0.mlp.0.weight', 'interactions.0.mlp.0.bias', 'interactions.0.mlp.2.weight', 'interactions.0.mlp.2.bias', 'interactions.0.conv.lin1.weight', 'interactions.0.conv.lin2.weight', 'interactions.0.conv.lin2.bias', 'interactions.0.conv.nn.0.weight', 'interactions.0.conv.nn.0.bias', 'interactions.0.conv.nn.2.weight', 'interactions.0.conv.nn.2.bias', 'interactions.0.lin.weight', 'interactions.0.lin.bias', 'interactions.1.mlp.0.weight', 'interactions.1.mlp.0.bias', 'interactions.1.mlp.2.weight', 'interactions.1.mlp.2.bias', 'interactions.1.conv.lin1.weight', 'interactions.1.conv.lin2.weight', 'interactions.1.conv.lin2.bias', 'interactions.1.conv.nn.0.weight', 'interactions.1.conv.nn.0.bias', 'interactions.1.conv.nn.2.weight', 'interactions.1.conv.nn.2.bias', 'interactions.1.lin.weight', 'interactions.1.lin.bias', 'interactions.2.mlp.0.weight', 'interactions.2.mlp.0.bias', 'interactions.2.mlp.2.weight', 'interactions.2.mlp.2.bias', 'interactions.2.conv.lin1.weight', 'interactions.2.conv.lin2.weight', 'interactions.2.conv.lin2.bias', 'interactions.2.conv.nn.0.weight', 'interactions.2.conv.nn.0.bias', 'interactions.2.conv.nn.2.weight', 'interactions.2.conv.nn.2.bias', 'interactions.2.lin.weight', 'interactions.2.lin.bias', 'interactions.3.mlp.0.weight', 'interactions.3.mlp.0.bias', 'interactions.3.mlp.2.weight', 'interactions.3.mlp.2.bias', 'interactions.3.conv.lin1.weight', 'interactions.3.conv.lin2.weight', 'interactions.3.conv.lin2.bias', 'interactions.3.conv.nn.0.weight', 'interactions.3.conv.nn.0.bias', 'interactions.3.conv.nn.2.weight', 'interactions.3.conv.nn.2.bias', 'interactions.3.lin.weight', 'interactions.3.lin.bias', 'interactions.4.mlp.0.weight', 'interactions.4.mlp.0.bias', 'interactions.4.mlp.2.weight', 'interactions.4.mlp.2.bias', 'interactions.4.conv.lin1.weight', 'interactions.4.conv.lin2.weight', 'interactions.4.conv.lin2.bias', 'interactions.4.conv.nn.0.weight', 'interactions.4.conv.nn.0.bias', 'interactions.4.conv.nn.2.weight', 'interactions.4.conv.nn.2.bias', 'interactions.4.lin.weight', 'interactions.4.lin.bias', 'interactions.5.mlp.0.weight', 'interactions.5.mlp.0.bias', 'interactions.5.mlp.2.weight', 'interactions.5.mlp.2.bias', 'interactions.5.conv.lin1.weight', 'interactions.5.conv.lin2.weight', 'interactions.5.conv.lin2.bias', 'interactions.5.conv.nn.0.weight', 'interactions.5.conv.nn.0.bias', 'interactions.5.conv.nn.2.weight', 'interactions.5.conv.nn.2.bias', 'interactions.5.lin.weight', 'interactions.5.lin.bias', 'lin1.weight', 'lin1.bias', 'lin2.weight', 'lin2.bias'], unexpected_keys=['encoder.embedding.weight', 'encoder.embedding.bias', 'encoder.distance_expansion.offset', 'encoder.interactions.0.mlp.0.weight', 'encoder.interactions.0.mlp.0.bias', 'encoder.interactions.0.mlp.2.weight', 'encoder.interactions.0.mlp.2.bias', 'encoder.interactions.0.conv.lin1.weight', 'encoder.interactions.0.conv.lin2.weight', 'encoder.interactions.0.conv.lin2.bias', 'encoder.interactions.0.conv.nn.0.weight', 'encoder.interactions.0.conv.nn.0.bias', 'encoder.interactions.0.conv.nn.2.weight', 'encoder.interactions.0.conv.nn.2.bias', 'encoder.interactions.0.lin.weight', 'encoder.interactions.0.lin.bias', 'encoder.interactions.1.mlp.0.weight', 'encoder.interactions.1.mlp.0.bias', 'encoder.interactions.1.mlp.2.weight', 'encoder.interactions.1.mlp.2.bias', 'encoder.interactions.1.conv.lin1.weight', 'encoder.interactions.1.conv.lin2.weight', 'encoder.interactions.1.conv.lin2.bias', 'encoder.interactions.1.conv.nn.0.weight', 'encoder.interactions.1.conv.nn.0.bias', 'encoder.interactions.1.conv.nn.2.weight', 'encoder.interactions.1.conv.nn.2.bias', 'encoder.interactions.1.lin.weight', 'encoder.interactions.1.lin.bias', 'encoder.interactions.2.mlp.0.weight', 'encoder.interactions.2.mlp.0.bias', 'encoder.interactions.2.mlp.2.weight', 'encoder.interactions.2.mlp.2.bias', 'encoder.interactions.2.conv.lin1.weight', 'encoder.interactions.2.conv.lin2.weight', 'encoder.interactions.2.conv.lin2.bias', 'encoder.interactions.2.conv.nn.0.weight', 'encoder.interactions.2.conv.nn.0.bias', 'encoder.interactions.2.conv.nn.2.weight', 'encoder.interactions.2.conv.nn.2.bias', 'encoder.interactions.2.lin.weight', 'encoder.interactions.2.lin.bias', 'encoder.interactions.3.mlp.0.weight', 'encoder.interactions.3.mlp.0.bias', 'encoder.interactions.3.mlp.2.weight', 'encoder.interactions.3.mlp.2.bias', 'encoder.interactions.3.conv.lin1.weight', 'encoder.interactions.3.conv.lin2.weight', 'encoder.interactions.3.conv.lin2.bias', 'encoder.interactions.3.conv.nn.0.weight', 'encoder.interactions.3.conv.nn.0.bias', 'encoder.interactions.3.conv.nn.2.weight', 'encoder.interactions.3.conv.nn.2.bias', 'encoder.interactions.3.lin.weight', 'encoder.interactions.3.lin.bias', 'encoder.interactions.4.mlp.0.weight', 'encoder.interactions.4.mlp.0.bias', 'encoder.interactions.4.mlp.2.weight', 'encoder.interactions.4.mlp.2.bias', 'encoder.interactions.4.conv.lin1.weight', 'encoder.interactions.4.conv.lin2.weight', 'encoder.interactions.4.conv.lin2.bias', 'encoder.interactions.4.conv.nn.0.weight', 'encoder.interactions.4.conv.nn.0.bias', 'encoder.interactions.4.conv.nn.2.weight', 'encoder.interactions.4.conv.nn.2.bias', 'encoder.interactions.4.lin.weight', 'encoder.interactions.4.lin.bias', 'encoder.interactions.5.mlp.0.weight', 'encoder.interactions.5.mlp.0.bias', 'encoder.interactions.5.mlp.2.weight', 'encoder.interactions.5.mlp.2.bias', 'encoder.interactions.5.conv.lin1.weight', 'encoder.interactions.5.conv.lin2.weight', 'encoder.interactions.5.conv.lin2.bias', 'encoder.interactions.5.conv.nn.0.weight', 'encoder.interactions.5.conv.nn.0.bias', 'encoder.interactions.5.conv.nn.2.weight', 'encoder.interactions.5.conv.nn.2.bias', 'encoder.interactions.5.lin.weight', 'encoder.interactions.5.lin.bias', 'encoder.lin1.weight', 'encoder.lin1.bias', 'encoder.lin2.weight', 'encoder.lin2.bias', 'decoder.residue_type.layers.layers.0.weight', 'decoder.residue_type.layers.layers.0.bias', 'decoder.residue_type.layers.layers.1.weight', 'decoder.residue_type.layers.layers.1.bias', 'decoder.residue_type.layers.layers.2.weight', 'decoder.residue_type.layers.layers.2.bias', 'featuriser.positional_encoding.frequency'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load\n",
    "\n",
    "chk_path = '/work3/s194408/Project/weight/ca_bb/last.ckpt'\n",
    "\n",
    "checkpoint  = torch.load(chk_path, map_location=torch.device('cpu'))\n",
    "\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try load the weight without using the module\n",
    "\n",
    "chk_path = '/work3/s194408/Project/weight/ca_bb/last.ckpt'\n",
    "\n",
    "# original saved file with DataParallel\n",
    "checkpoint = torch.load(chk_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "from collections import OrderedDict\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in checkpoint.items():\n",
    "    name = key.replace(\"module.\", \"\") # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "# load params\n",
    "model.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd71c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
